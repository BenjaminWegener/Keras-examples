{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "superresolution_deeper_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y52zwvlpHvCC"
      },
      "source": [
        "## superresolution (deeper net / more layers)\n",
        "single image superresolution (4x zoom)\n",
        "- channel attention mechanism [[paper]](https://arxiv.org/abs/1807.02758)\n",
        "- residual in residual architecture [[paper]](https://arxiv.org/abs/1505.04597)\n",
        "- subpixel convolution / pixelshuffle [[paper]](https://arxiv.org/abs/1609.05158)\n",
        "- running on [tensorflow/google colab](https://colab.research.google.com/) AND on [plaidml](https://www.intel.ai/plaidml/)\n",
        "- using the famous [Set14](https://www.google.com/search?q=set14) dataset ONLY (with heavy augmentation) - no validation needed\n",
        "\n",
        "jupyter notebook by [Benjamin Wegener](https://scholar.google.de/citations?user=yEn9St8AAAAJ) from [github](https://www.github.com/BenjaminWegener/keras-examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s-U33BDYHvCF"
      },
      "source": [
        "### options\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bDQFzxuJHvCH",
        "colab": {}
      },
      "source": [
        "run_on_google_colab = True #use PlaidML as Backend, change this to 'True' to run on colab/tf\n",
        "epochs = 25 #Number of epochs to train\n",
        "scale = 4 #How much should we upscale images\n",
        "channels = 3 #channels of low resolution image\n",
        "batch_size = 14 #what batch-size should we use (decrease if you encounter video memory errors)\n",
        "steps_per_epoch = 5000 #How much iterations per epoch to train\n",
        "height_lr = 128 #height of low resolution image\n",
        "width_lr = height_lr #width of low resolution image\n",
        "gen_lr = 0.001 #learning rate of generator\n",
        "logging_steps = 100 #how often to update the training log\n",
        "height_hr = int(height_lr * scale) # High-resolution image height\n",
        "width_hr = int(width_lr * scale) # High-resolution image width"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GzyzlkF3HvCL"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v78MsA4CHvCM",
        "outputId": "e021c5b9-7218-4c6f-f559-178c88641fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "if run_on_google_colab:\n",
        "    %cd /content\n",
        "    !git clone https://github.com/BenjaminWegener/keras-examples #download Dataset\n",
        "    %cd keras-examples\n",
        "else:\n",
        "    os.environ['KERAS_BACKEND'] = 'plaidml.keras.backend'\n",
        "import numpy as np\n",
        "from keras.models import Model, Input, load_model\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.callbacks import LambdaCallback\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "%matplotlib inline    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WyQf_dwWHvCR"
      },
      "source": [
        "### function for image visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ygs-7DxwHvCS",
        "colab": {}
      },
      "source": [
        "def show(tensors):\n",
        "    plt.rcParams['figure.figsize'] = [20, 10]\n",
        "    fig = plt.figure()\n",
        "    for i in range(len(tensors)):\n",
        "        try:\n",
        "            tensors[i] = np.squeeze(tensors[i], axis = 0)\n",
        "        except:\n",
        "            pass\n",
        "        tensors[i] = (tensors[i] + 1.) * 127.5\n",
        "        fig.add_subplot(1,len(tensors), i + 1)\n",
        "        plt.imshow(tensors[i].astype(np.uint8), interpolation = 'nearest')\n",
        "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SJi-rBgoHvCU"
      },
      "source": [
        "### dataset function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m5lxEgg6HvCV",
        "colab": {}
      },
      "source": [
        "# return batch of augmented train and target images with quantity n_samples\n",
        "def get_batch(n_samples, height, width, channels):\n",
        "    # define a ImageGenerator instance from keras with augmentations\n",
        "    image_gen = ImageDataGenerator(rotation_range=360,\n",
        "                           width_shift_range=0.5,\n",
        "                           height_shift_range=0.5,\n",
        "                           zoom_range=[0.2, 0.7],\n",
        "                           horizontal_flip=True,\n",
        "                           vertical_flip=True,\n",
        "                           fill_mode='reflect',\n",
        "                           data_format='channels_last',\n",
        "                           brightness_range=[0.5, 1.5])\n",
        "    #seed for random augmentations\n",
        "    random_seed = int(random.random() * 100000)\n",
        "    #generate augmented images\n",
        "    y_train = image_gen.flow_from_directory('.', target_size = (height * scale, width * scale), batch_size = n_samples, class_mode = None, seed = random_seed)\n",
        "    y_train = y_train.__getitem__(0).copy() #fix for 'array doesn't own its data'\n",
        "    x_train = np.empty((len(y_train), height, width, channels))\n",
        "    for i in range(n_samples):\n",
        "        # source images are zoomed to 25%\n",
        "        input_size = height * scale\n",
        "        output_size = height\n",
        "        fraction = input_size // output_size\n",
        "        x_train[i] = y_train[i].reshape((output_size, fraction, output_size, fraction, channels)).mean(3).mean(1)\n",
        "    #normalize images to [-1, 1]\n",
        "    x_train = x_train/127.5 - 1.\n",
        "    y_train = y_train/127.5 - 1.\n",
        "    return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A9P-WqYbHvCX"
      },
      "source": [
        "### base functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tdeUTBRaHvCY",
        "colab": {}
      },
      "source": [
        "def fast_normalization(x): # use clipping instead of batchnormalization for network stabilization\n",
        "    return Lambda(lambda x: K.clip(x, -1, 1), output_shape=lambda s: (s[0], s[1], s[2], s[3]))(x)\n",
        "\n",
        "def residual_block(inputs): #combined pixel shuffle and squeeze\n",
        "    x = inputs\n",
        "    x = Conv2D(32, kernel_size = 9, activation = 'tanh', padding = 'same', strides = 2)(x)\n",
        "    x = SeparableConv2D(128, kernel_size = 9, activation = 'relu', padding = 'same')(x) # rapidly increase speed at slightly worse results\n",
        "    x = fast_normalization(x)\n",
        "    x = Lambda(lambda x: K.reshape(x, (K.shape(x)[0], K.shape(x)[1], K.shape(x)[2], 32, 2, 2)), output_shape = lambda s: (s[0], s[1], s[2], s[3] // 4, 2, 2))(x)\n",
        "    x = Permute((3, 2, 4, 1, 5))(x)\n",
        "    x = Lambda(lambda x: K.reshape(x, (K.shape(x)[0], K.shape(x)[1], K.shape(x)[2] * K.shape(x)[3], K.shape(x)[4] * K.shape(x)[5])), output_shape = lambda s: (s[0], s[1], s[2] * s[3], s[4] * s[5]))(x)\n",
        "    x = Permute((3, 2, 1))(x)\n",
        "    #---\n",
        "    x1 = x\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(8, activation = 'relu')(x) #reduction like in RCAN \n",
        "    x = Dense(32, activation = 'hard_sigmoid')(x)\n",
        "    x = Reshape((1, 1, 32))(x)\n",
        "    x = Multiply()([x1, x])\n",
        "    x = Add()([inputs, x]) \n",
        "    return x\n",
        "\n",
        "def upsample(inputs): #combined pixel shuffle and squeeze with 2x upscale\n",
        "    x = inputs\n",
        "    x = Conv2D(12, kernel_size = 9, activation = 'tanh', padding = 'same', strides = 1)(x)\n",
        "    x = fast_normalization(x)\n",
        "    x = Lambda(lambda x: K.reshape(x, (K.shape(x)[0], K.shape(x)[1], K.shape(x)[2], 3, 2, 2)), output_shape = lambda s: (s[0], s[1], s[2], s[3] // 4, 2, 2))(x)\n",
        "    x = Permute((3, 2, 4, 1, 5))(x)\n",
        "    x = Lambda(lambda x: K.reshape(x, (K.shape(x)[0], K.shape(x)[1], K.shape(x)[2] * K.shape(x)[3], K.shape(x)[4] * K.shape(x)[5])), output_shape = lambda s: (s[0], s[1], s[2] * s[3], s[4] * s[5]))(x)\n",
        "    x = Permute((2, 3, 1))(x)\n",
        "    #---\n",
        "    x1 = x\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(2, activation = 'relu')(x) #reduction like in RCAN \n",
        "    x = Dense(3, activation = 'hard_sigmoid')(x)\n",
        "    x = Reshape((1, 1, 3))(x)\n",
        "    x = Multiply()([x1, x])\n",
        "    #x = Add()([inputs, x]) #can't skip connection here, needs to upsample\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gvy5AbKwHvCi"
      },
      "source": [
        "### build generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SKFcfdh_HvCf",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "x = inputs = Input(shape = (height_lr, width_lr, channels))\n",
        "x = Conv2D(32, kernel_size = 3, padding = 'same', activation = 'tanh')(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = Conv2D(3, kernel_size = 3, padding = 'same', activation = 'tanh')(x)\n",
        "x = fast_normalization(x)\n",
        "x = upsample(x)\n",
        "x = upsample(x)\n",
        "\n",
        "generator = Model(inputs = inputs, outputs = x)\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EmBC-aMQHvCk"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hkYfqMpN2MIQ",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "#load checkpoint & compile the generator network\n",
        "print('trying to load last saved weights...', end = ' ')\n",
        "try:\n",
        "    generator.load_weights('superresolution_deeper_net_weights')\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed')\n",
        "    pass\n",
        "\n",
        "generator.compile(optimizer = Adam(gen_lr), loss = 'mae')\n",
        "\n",
        "# Train generator\n",
        "def logging(epoch, logs):\n",
        "    if epoch % logging_steps == 0:\n",
        "        testX, testY = get_batch(1, height_lr, width_lr, channels)\n",
        "        clear_output()\n",
        "        print('epoch', real_epoch + 1, '/', epochs, '--> step', epoch, '/', steps_per_epoch, ': loss', logs['loss'])\n",
        "        testZ = generator.predict(testX)\n",
        "        show([testX, testZ, testY])\n",
        "        print('test_loss:', generator.evaluate(testX, testY, verbose = 0))\n",
        "logging_callback = LambdaCallback(\n",
        "    on_epoch_end=lambda epoch, logs: logging(epoch, logs)\n",
        ")\n",
        "for real_epoch in range(epochs):\n",
        "    X, Y = get_batch(batch_size, height_lr, width_lr, channels)\n",
        "    generator.fit(X, Y, batch_size, epochs = steps_per_epoch, verbose = 0, callbacks = [logging_callback], shuffle = True)\n",
        "    try:\n",
        "        print('trying to save weights...', end = ' ')\n",
        "        generator.save_weights('superresolution_deeper_net_weights')\n",
        "    except:\n",
        "        print('failed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xo-_GBp6NE8s"
      },
      "source": [
        "### validate on complete picture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP04S4f1l0qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show image in actual size https://stackoverflow.com/a/42314798/\n",
        "def display_image_in_actual_size(im_data):\n",
        "    dpi = 100\n",
        "    height, width, depth = im_data.shape\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im_data, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XzRnnhw6fRkH",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "img = np.array(Image.open('./Set14/lenna.png'))\n",
        "img = img /127.5 -1\n",
        "x = inputs = Input(shape = img.shape)\n",
        "x = Conv2D(32, kernel_size = 3, padding = 'same', activation = 'tanh')(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = residual_block(x)\n",
        "x = Conv2D(3, kernel_size = 3, padding = 'same', activation = 'tanh')(x)\n",
        "x = fast_normalization(x)\n",
        "x = upsample(x)\n",
        "x = upsample(x)\n",
        "generator = Model(inputs = inputs, outputs = x)\n",
        "print('trying to load last saved weights...', end = ' ')\n",
        "try:\n",
        "    generator.load_weights('superresolution_deeper_net_weights')\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed')\n",
        "    pass\n",
        "predicted = generator.predict(np.expand_dims((img), 0))\n",
        "print('ground truth:')\n",
        "img = (img + 1) * 127.5\n",
        "display_image_in_actual_size(img.astype(np.uint8))\n",
        "print('superresolution:')\n",
        "predicted = np.squeeze(predicted)\n",
        "predicted = (predicted + 1) * 127.5\n",
        "display_image_in_actual_size(predicted.astype(np.uint8))\n",
        "predicted = Image.fromarray(predicted.astype(np.uint8))\n",
        "print('trying to save image as \\'superresolution_deeper_net_result.png\\'...', end = ' ')\n",
        "try:\n",
        "    predicted.save('superresolution_deeper_net_result.png', \"PNG\")\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}